{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing #mention the path where the files are located\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traindatalength: 800\n",
      "testdatalength : 350\n"
     ]
    }
   ],
   "source": [
    "with open('train.dat','r') as train:\n",
    " traindatalength = train.readlines()\n",
    "print(\"traindatalength:\" ,len(traindatalength))\n",
    "\n",
    "with open('test.dat','r') as test:\n",
    " testdatalength = test.readlines()\n",
    "print(\"testdatalength :\" ,len(testdatalength))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset = np.zeros((800,100001)) #building train matrix\n",
    "activity = []\n",
    "with open('train.dat', 'r') as t:   \n",
    "     i = 0\n",
    "     for row in t:\n",
    "         row_list = row.split('\\t')\n",
    "         activity.append(row_list[0])\n",
    "         for item in row_list[1].split():\n",
    "             trainset[i][int(item)] = 1\n",
    "             #print int(item)\n",
    "         i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testset = np.zeros((350,100001)) #building test matrix\n",
    "\n",
    "with open('test.dat', 'r') as s:   \n",
    "     i = 0\n",
    "     for row in s:\n",
    "         row_list = row.split('\\t')\n",
    "         for item in row_list[0].split():\n",
    "             testset[i][int(item)] = 1\n",
    "         i = i + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD #performing dimension reduction\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "svd = TruncatedSVD(n_components=800,n_iter=7,random_state=42)\n",
    "svd.fit(trainset)\n",
    "reduceddata=svd.transform(trainset)\n",
    "Reduced_data1 = svd.transform(testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf =  AdaBoostClassifier(n_estimators=1000,learning_rate=1.5)\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.linear_model import Perceptron\n",
    "#clf = Perceptron()\n",
    "X,y = reduceddata , activity\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '0' '1' '0' '0' '0' '0' '1' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '1' '1' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '1' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0'\n",
      " '0' '1' '0' '0' '1' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '1'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '1' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '1' '1'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '1' '0' '0' '0' '0' '1' '1' '1' '1' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0'\n",
      " '1' '0' '0' '0' '0' '0' '1' '0']\n"
     ]
    }
   ],
   "source": [
    "final = []\n",
    "final= clf.fit(X,y).predict(Reduced_data1)\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('format.dat', 'w') \n",
    "#mention the location where the file must be saved\n",
    "i=0\n",
    "#f.write('randomforest accuracy was not good' +'\\n')\n",
    "for Value in final:\n",
    "    f.write(Value +'\\n')\n",
    "    i+=1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
